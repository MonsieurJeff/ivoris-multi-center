# Unified Presentation Script

**Ivoris Pipeline + Multi-Center** | Loom Recording | ~7 minutes

---

## Overview

| Section | Duration | Project | What to Show |
|---------|----------|---------|--------------|
| 1. Opening | 15 sec | - | Hook with both challenges |
| 2. The Ask | 30 sec | pipeline | German requirement |
| 3. The Solution | 1.5 min | pipeline | Extract + show output |
| 4. The Pivot | 30 sec | - | "But what about 30 centers?" |
| 5. The Chaos | 1 min | multi-center | discover-raw |
| 6. The Extension | 1.5 min | multi-center | Mapping + extraction |
| 7. The Proof | 1 min | multi-center | Benchmark |
| 8. Wrap Up | 30 sec | - | Summary |

**Total: ~7 minutes**

---

## Section 1: Opening (15 seconds)

**Show:** Terminal or title slide

**Say:**
> "I was asked to build a daily extraction pipeline for Ivoris dental software. I built that. Then I asked myself: what happens at scale? What if there are 30 centers, each with completely different schema names? Let me show you both solutions."

**Transition:** Navigate to ivoris-pipeline

---

## Section 2: The Ask (30 seconds)

**Project:** ivoris-pipeline

**Show:** CHALLENGE.md or README

**Say:**
> "Here's the original requirement, in German..."

**Read/Show:**
> "Extraction-Pipeline für Ivoris bauen. Datenbedarf: Datum, Pat-ID, Versicherungsstatus, Karteikarteneintrag, Leistungen."

**Say:**
> "Build an extraction pipeline. When users make chart entries, transfer the data daily. Five required fields: Date, Patient ID, Insurance Status, Chart Entry, and Service Codes. Output in CSV or JSON."

**Key points:**
- Show the German text (authenticity)
- Translate briefly
- Emphasize the 5 required fields

---

## Section 3: The Solution (1.5 minutes)

**Project:** ivoris-pipeline

**Show:** Terminal

### 3.1 Navigate to Project

```bash
cd ~/Projects/outre_base/sandbox/ivoris-pipeline
```

### 3.2 Run Extraction

```bash
python src/main.py --daily-extract --date 2022-01-18
```

**Say:**
> "One command. Extract yesterday's chart entries - or any specific date."

### 3.3 Show Output

```bash
cat data/output/ivoris_chart_entries_2022-01-18.json
```

**Say:**
> "Clean JSON output. All five required fields: date, patient_id, insurance_status, chart_entry, service_codes."

**Point out:**
- Metadata section (timestamp, record count)
- Insurance status mapping (GKV = public, PKV = private)
- German characters handled correctly (UTF-8)

### 3.4 The Result

**Say:**
> "All acceptance criteria met. Clean architecture - database adapter, extraction service, data model. The main challenge is complete."

**PAUSE.** Let this land.

---

## Section 4: The Pivot (30 seconds)

**This is the critical moment.**

**Say (with energy):**
> "So the main challenge is done. But then I started thinking..."
>
> "Clinero doesn't manage one dental practice. They manage many. What happens when you need to extract from 30 centers?"

**Build tension:**
> "And here's the thing about Ivoris that makes this interesting: each installation can have **randomly generated** table and column names."

**Say:**
> "KARTEI_MN in Munich. KARTEI_8Y in Berlin. KARTEI_XQ4 in Hamburg. No two centers have the same schema."

**Transition:**
> "I decided to solve this properly. Let me show you."

---

## Section 5: The Chaos (1 minute)

**Project:** ivoris-multi-center

**Show:** Terminal

### 5.1 Navigate to Project

```bash
cd ~/Projects/outre_base/sandbox/ivoris-multi-center
```

### 5.2 List Centers

```bash
python -m src.cli list
```

**Say:**
> "30 centers configured. 20 in Germany, 5 in Austria, 5 in Switzerland. Each with its own database and unique schema."

### 5.3 Show Raw Discovery

```bash
python -m src.cli discover-raw -c center_01
```

**Say:**
> "Raw schema discovery. See the random suffixes? KARTEI_MN, PATNR_NAN6, DATUM_3A4. Every table, every column has random characters appended."

**Let them absorb the chaos.**

> "You can't write one SQL query that works everywhere. Every center needs different column names."

---

## Section 6: The Extension (1.5 minutes)

**Project:** ivoris-multi-center

### 6.1 Explain the Solution

**Say:**
> "My solution: pattern-based discovery. Four stages."

**Briefly explain:**
> "First, raw discovery - see what's there. Second, pattern matching - strip the random suffix, find the canonical name. Third, human review - every mapping has a 'reviewed: false' flag. In production, a human verifies before extraction. Fourth, parallel execution - all 30 centers at once."

### 6.2 Show Mapping

```bash
python -m src.cli show-mapping center_01
```

**Say:**
> "Here's what the mapping looks like. Canonical names on the left, actual database names on the right. Auto-generated by pattern matching."

**Point out:**
- `reviewed: false` flag
- Table mappings (KARTEI → KARTEI_MN)
- Column mappings (PATNR → PATNR_NAN6)

**Say:**
> "The key insight: even random names follow a pattern. KARTEI_MN still has KARTEI in it."

### 6.3 Extract from One Center

```bash
python -m src.cli extract --date 2022-01-18 -c center_01
```

**Say:**
> "Same unified output format, regardless of which center."

---

## Section 7: The Proof (1 minute)

**Project:** ivoris-multi-center

### 7.1 Run Benchmark

```bash
python -m src.cli benchmark
```

**Say:**
> "Now the real test. All 30 centers in parallel."

**Wait for results. Let them sink in.**

### 7.2 Highlight Results

**Say:**
> "466 milliseconds for 30 centers. The target was 5 seconds. Ten times faster than required."

**Point out:**
- Total time
- Per-center breakdown
- PASS indicator

### 7.3 (Optional) Show Web UI

```bash
python -m src.cli web
```

> "For visual exploration, there's a web UI. Browse centers, view mappings, run benchmarks."

**Only if time permits - can skip to wrap-up.**

---

## Section 8: Wrap Up (30 seconds)

**Say:**
> "To summarize..."

**Main challenge:**
> "The daily extraction pipeline - all 5 required fields, CSV and JSON output, clean architecture. Done."

**Extension:**
> "The multi-center solution - 30 databases with random schemas, pattern-based discovery, human review workflow, parallel extraction in 466 milliseconds."

**Close with confidence:**
> "That's both challenges complete. The extraction pipeline you asked for, plus a scalable solution that handles schema chaos. Thank you for watching."

---

## Recording Tips

### Before Recording

- [ ] Both projects working (run pre-flight checks)
- [ ] Terminal font: 16pt+
- [ ] Know the pivot line by heart
- [ ] Practice the transition from pipeline → multi-center
- [ ] Close notifications

### During Recording

- **Pace:** Pause after key moments (pivot, benchmark results)
- **Energy:** Higher energy at the pivot and results
- **Cursor:** Move slowly, deliberately
- **Errors:** If something fails, stay calm and explain

### Terminal Setup

Keep two terminal tabs ready:
- Tab 1: `cd ~/Projects/outre_base/sandbox/ivoris-pipeline`
- Tab 2: `cd ~/Projects/outre_base/sandbox/ivoris-multi-center`

---

## Emergency Recovery

### If Pipeline Extraction Fails

```bash
cd ~/Projects/outre_base/sandbox/ivoris-pipeline
./scripts/restore-database.sh
python src/main.py --daily-extract --date 2022-01-18
```

### If Multi-Center Benchmark Fails

```bash
cd ~/Projects/outre_base/sandbox/ivoris-multi-center
python scripts/generate_test_dbs.py
python -m src.cli generate-mappings
python -m src.cli benchmark
```

### If Docker is Down

```bash
docker-compose up -d
sleep 30
# Then retry
```

---

## Backup Plan

If something goes catastrophically wrong:

1. **Acknowledge it calmly:** "Let me show you what this would normally produce..."
2. **Show the output files:** `cat data/output/...`
3. **Explain the architecture:** Talk through what should happen
4. **Keep confidence:** "The code works - happy to debug this live or show you the test results"
