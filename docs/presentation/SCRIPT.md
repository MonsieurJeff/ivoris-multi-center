# Presentation Script

**Ivoris Multi-Center Pipeline** | Loom Recording | 5-7 minutes

---

## Overview

| Section | Duration | What to Show |
|---------|----------|--------------|
| 1. Hook | 15 sec | Title slide or README |
| 2. Problem | 30 sec | Schema examples |
| 3. Architecture | 1 min | Diagram or terminal |
| 4. CLI Demo | 2 min | Terminal commands |
| 5. Web UI Demo | 2 min | Browser |
| 6. Results | 30 sec | Benchmark output |
| 7. Wrap Up | 15 sec | Summary |

**Total: ~6.5 minutes**

---

## Section 1: Hook (15 seconds)

**Show:** Project title or README header

**Say:**
> "I built a data extraction pipeline that handles 30 dental databases - each with completely random table and column names. Let me show you how it works."

**Transition:** Open terminal

---

## Section 2: Problem Statement (30 seconds)

**Show:** Terminal with `discover-raw` output or slide

**Say:**
> "Here's the challenge: 30 dental centers across Germany, Austria, and Switzerland. Each center runs the same Ivoris software, but every database has randomly generated schema names."

**Run:**
```bash
python -m src.cli discover-raw -c center_01 | head -20
```

**Say:**
> "See? Tables like `KARTEI_MN` instead of just `KARTEI`. And every column has its own random suffix too - `PATNR_NAN6`, `DATUM_3A4`. No pattern across centers. You can't write static SQL."

**Key points to hit:**
- 30 centers, each unique
- Random table suffixes (2-4 chars)
- Random column suffixes (independent of table)
- Same logical data, different physical names

---

## Section 3: Architecture (1 minute)

**Show:** Terminal or draw as you explain

**Say:**
> "My solution has four stages..."

**Draw/explain:**
```
30 Databases → Raw Discovery → Mapping Files → Parallel Extraction → Unified Output
```

**Say:**
> "First, **raw discovery** - I query `INFORMATION_SCHEMA` to see what tables and columns actually exist. No interpretation, just facts."

> "Second, **mapping generation** - pattern matching to figure out that `KARTEI_MN` means `KARTEI`, and `PATNR_NAN6` means `PATNR`. This creates JSON mapping files."

> "Third, the key part - **manual review workflow**. Every mapping file has a `reviewed: false` flag. In production, a human would verify the mapping before extraction. Safety first."

> "Finally, **parallel extraction** using ThreadPoolExecutor. All 30 centers at once, unified into a single canonical format."

**Key architectural decisions to mention:**
- JSON mapping files (human-readable, version-controllable)
- `reviewed` flag (production safety)
- Ground truth separation (validation)
- Pattern-based, not hardcoded

---

## Section 4: CLI Demo (2 minutes)

**Show:** Terminal (large font, 16pt+)

### 4.1 List Centers

```bash
python -m src.cli list
```

**Say:**
> "30 centers configured - 20 in Germany, 5 in Austria, 5 in Switzerland. Each with its own database."

### 4.2 Raw Discovery

```bash
python -m src.cli discover-raw -c center_01
```

**Say:**
> "Raw discovery shows exactly what's in the database. See the random suffixes? `KARTEI_MN`, `PATNR_NAN6`. Every center is different."

### 4.3 Show Mapping

```bash
python -m src.cli show-mapping center_01
```

**Say:**
> "The mapping file shows canonical to actual. `KARTEI` maps to `KARTEI_MN`. `PATNR` maps to `PATNR_NAN6`. This was auto-generated by pattern matching."

**Point out:**
- `reviewed: false` flag
- Table mappings
- Column mappings

### 4.4 Extract Data

```bash
python -m src.cli extract --date 2022-01-18 -c center_01
```

**Say:**
> "Extraction uses the mapping to build the right SQL. Output is in canonical format - same structure regardless of which center."

### 4.5 Benchmark

```bash
python -m src.cli benchmark
```

**Say:**
> "The benchmark runs all 30 centers in parallel. Target was under 5 seconds... and we're at about 400 milliseconds. Ten times faster than required."

**Wait for output, then point out:**
- Total time
- Per-center timing
- PASS indicator

---

## Section 5: Web UI Demo (2 minutes)

**Start server:**
```bash
python -m src.cli web
```

**Open:** http://localhost:8000

**Say:**
> "For the supplemental challenge, I built a web UI. Three main pages..."

### 5.1 Explore Page

**Navigate to:** Explore Centers

**Actions:**
1. Select a center from dropdown
2. Show center details
3. Point out the mapping table
4. Load data for a date

**Say:**
> "Explore lets you browse individual centers. Here's the schema mapping - canonical names on the left, actual database names on the right."

### 5.2 Metrics Dashboard

**Navigate to:** Metrics Dashboard

**Actions:**
1. Click "Select All"
2. Click "Benchmark"
3. Wait for results
4. Point out summary cards
5. Show chart
6. Click "Export JSON"

**Say:**
> "The metrics dashboard lets you benchmark multiple centers. Select all 30, run the benchmark, and you get a full breakdown - total time, entries per center, and a visualization."

### 5.3 Schema Diff

**Navigate to:** Schema Diff

**Actions:**
1. Select a center
2. Click "Compare"
3. Show accuracy percentage
4. Point out green checkmarks

**Say:**
> "Schema Diff compares what we discovered against ground truth - what the generator actually created. This validates the pattern matching is working correctly."

### 5.4 Dark Mode (Quick)

**Action:** Toggle dark mode

**Say:**
> "And yes, dark mode works."

---

## Section 6: Results Summary (30 seconds)

**Show:** Terminal with benchmark results or summary slide

**Say:**
> "To summarize what we achieved..."

**Key metrics:**
- 30 dental centers
- Random schemas per center
- Pattern-based discovery (no manual mapping)
- Manual review workflow for safety
- <500ms extraction (target was 5s)
- Web UI with metrics and validation

**Tech stack:**
- Python 3.11
- FastAPI + Jinja2
- SQL Server (Docker)
- ThreadPoolExecutor
- Tailwind CSS, Chart.js

---

## Section 7: Wrap Up (15 seconds)

**Say:**
> "That's the Ivoris Multi-Center Pipeline - 30 databases with random schemas, unified through pattern-based discovery and parallel extraction. Thanks for watching, happy to answer any questions."

---

## Recording Tips

### Before Recording

- [ ] Docker running: `docker ps | grep ivoris`
- [ ] Databases exist: `python -m src.cli list`
- [ ] Mappings exist: `ls data/mappings/`
- [ ] Terminal font: 16pt+
- [ ] Browser zoom: 125%
- [ ] Close notifications
- [ ] Hide dock/taskbar

### During Recording

- **Pace:** Pause after key points
- **Cursor:** Move slowly, deliberately
- **Errors:** If something fails, explain and recover
- **Energy:** Start strong, stay engaged

### Terminal Setup

```bash
# Clean terminal
clear

# Make sure we're in the right directory
cd sandbox/ivoris-multi-center

# Test one command first
python -m src.cli list
```

---

## Backup Commands

If something goes wrong:

```bash
# Full reset
docker-compose down -v
docker-compose up -d
sleep 30
python scripts/generate_test_dbs.py
python -m src.cli generate-mappings

# Just regenerate mappings
python -m src.cli generate-mappings

# Kill stuck web server
pkill -f "uvicorn"
```
