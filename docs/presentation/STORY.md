# The Story

**Unified 5-Act Narrative: "The Challenge and Beyond"**

This document helps you tell a compelling story that covers both projects.

---

## The Five-Act Structure

```
ACT 1: THE ASK           →  "Here's what they asked for"
ACT 2: THE SOLUTION      →  "Here's what I built"
ACT 3: THE QUESTION      →  "But what about scale?"
ACT 4: THE EXTENSION     →  "Here's how I went further"
ACT 5: THE PROOF         →  "Here's the evidence it all works"
```

---

## Act 1: The Ask (Setup)

**Project:** ivoris-pipeline

### The Hook (First 15 seconds)

Start with the original requirement:

> "I was asked to build a daily extraction pipeline for Ivoris dental software. Let me show you the original requirement..."

### Show the Requirement

Display the German text (from CHALLENGE.md):

> **"Extraction-Pipeline für Ivoris bauen"**
>
> Anforderung: Wenn User einen Karteikarteneintrag machen, soll täglich ein Update/Datenübertrag vorgenommen werden.
>
> Datenbedarf: Datum, Pat-ID, Versicherungsstatus, Karteikarteneintrag, Leistungen (Ziffern)
>
> Output: csv/json

### Translate for Clarity

> "Build an extraction pipeline for Ivoris. When users make chart entries, transfer the data daily. Five fields needed: Date, Patient ID, Insurance Status, Chart Entry, and Service Codes. Output in CSV or JSON."

### Why This Matters

> "This is the core of any dental practice management integration - getting patient data out of Ivoris in a clean, automated way."

---

## Act 2: The Solution (The Main Challenge)

**Project:** ivoris-pipeline

### Show the Implementation

> "So I built it. Docker container for SQL Server, Python extraction service, clean data model."

**Demo commands:**
```bash
cd ~/Projects/outre_base/sandbox/ivoris-pipeline

# Show it works
python src/main.py --daily-extract --date 2022-01-18

# Show the output
cat data/output/ivoris_chart_entries_2022-01-18.json
```

### Walk Through the Output

Point out:
- All 5 required fields present
- Insurance status correctly mapped (GKV/PKV/Selbstzahler)
- Service codes linked to entries
- Clean JSON structure with metadata

### The Architecture (Brief)

> "The architecture is straightforward: database adapter, extraction service, data model. Nothing fancy - just clean, testable code."

```
Ivoris DB → Extraction Service → CSV/JSON Output
```

### The Result

> "All acceptance criteria met. The main challenge is complete."

**Pause here.** Let this land before the pivot.

---

## Act 3: The Question (The Pivot)

**This is the critical transition moment.**

### Set Up the Scale Problem

> "So the main challenge is done. But then I started thinking..."

> "Clinero doesn't manage one dental practice. They manage many. What happens when you need to extract from 30 centers? 50? 100?"

### Reveal the Real Problem

> "And here's the thing about Ivoris that makes this interesting..."

**Dramatic reveal:**

> "Each Ivoris installation can have **randomly generated** table and column names."

### Show What That Means

| Center | Table Name | Column Names |
|--------|------------|--------------|
| Munich | `KARTEI_MN` | `PATNR_NAN6`, `DATUM_3A4` |
| Berlin | `KARTEI_8Y` | `PATNR_DZ`, `DATUM_QW2` |
| Hamburg | `KARTEI_XQ4` | `PATNR_R2Z5`, `DATUM_7M` |
| ... | ... | ... |

> "No two centers have the same schema. You can't write one SQL query that works everywhere."

### The Stakes

> "So what do you do? Hardcode 30 different mappings? That doesn't scale. Breaks when schemas change. Error-prone."

### The Transition

> "I decided to solve this properly. Let me show you what I built."

---

## Act 4: The Extension (The Multi-Center Solution)

**Project:** ivoris-multi-center

### Show the Chaos

```bash
cd ~/Projects/outre_base/sandbox/ivoris-multi-center

# See what's actually in a database
python -m src.cli discover-raw -c center_01
```

> "This is raw schema discovery. See the random suffixes? Every table, every column has its own random characters."

### Explain the Solution

> "My solution has four stages:"

**Stage 1: Raw Discovery**
> "Query INFORMATION_SCHEMA to see what actually exists. No assumptions, just facts."

**Stage 2: Pattern Matching**
> "Find the canonical name within the random name. `KARTEI_MN` → `KARTEI`. Strip the suffix, find the pattern."

**Stage 3: Human Review**
> "Here's the key architectural decision - I don't trust the pattern matching blindly. Every mapping file has a `reviewed: false` flag. In production, a human verifies before extraction runs."

**Stage 4: Parallel Extraction**
> "All 30 centers at once using ThreadPoolExecutor. Each uses its own mapping, outputs to unified format."

### Show the Mapping

```bash
python -m src.cli show-mapping center_01
```

> "See? Canonical names on the left, actual database names on the right. Auto-generated by pattern matching."

**Point out the `reviewed: false` flag.**

### Run the Benchmark

```bash
python -m src.cli benchmark
```

> "Now let's see if it actually works at scale..."

**Wait for results. Let them sink in.**

> "466 milliseconds for 30 centers. The target was 5 seconds. Ten times faster."

---

## Act 5: The Proof (Resolution)

### Summarize Both Solutions

| Challenge | Solution | Result |
|-----------|----------|--------|
| **Main:** Daily extraction | ivoris-pipeline | All 5 fields, CSV/JSON |
| **Extension:** 30 random schemas | ivoris-multi-center | 466ms, pattern-based |

### The Key Architectural Decisions

> "A few decisions that matter for production:"

1. **JSON mapping files** - Human-readable, git-trackable, debuggable
2. **`reviewed` flag** - Catch mapping errors before they corrupt data
3. **Pattern-based discovery** - Handles any schema variation
4. **Zero code changes to add centers** - Just configuration

### The Numbers

```
Main Challenge:
  - 5 required fields extracted
  - All acceptance criteria met
  - Production-ready in ~3 hours

Extension:
  - 30 dental centers
  - 30 unique schemas
  - <500ms total extraction
  - 100% pattern match accuracy
  - 0 hardcoded mappings
```

### The Transformation

> "Before: One hardcoded extraction that doesn't scale."
>
> "After: A system that handles any number of centers with any schema variation."

---

## Emotional Beats

### Where to Pause

1. **After "The main challenge is complete"** - Let it land before pivoting
2. **After revealing random schemas** - Let them feel the problem
3. **After the `reviewed: false` explanation** - Shows production thinking
4. **After benchmark results** - Let the numbers sink in

### Where to Add Energy

1. **The pivot question** - "But what about 30 centers?"
2. **The reveal** - "Randomly generated table names"
3. **The solution** - "Pattern-based discovery"
4. **The results** - "Ten times faster than required"

### Where to Stay Calm

1. **Technical explanations** - Clear and steady
2. **Demo commands** - Deliberate, not rushed
3. **Error recovery** - If something breaks, stay composed

---

## Key Messages (What They Should Remember)

If they remember only FOUR things:

1. **Main challenge: Complete** - Daily extraction pipeline works
2. **Extension: Scale** - 30 centers with random schemas
3. **Solution: Systematic** - Pattern-based discovery, not hardcoding
4. **Safety: Built-in** - Human review before extraction

---

## Transitions

### Act 1 → Act 2 (Ask → Solution)
> "So I built it..."

### Act 2 → Act 3 (Solution → Question)
> "The main challenge is complete. But then I started thinking..."

### Act 3 → Act 4 (Question → Extension)
> "I decided to solve this properly. Let me show you."

### Act 4 → Act 5 (Extension → Proof)
> "Let's see if it actually works at scale..."

### Closing
> "That's both challenges complete. Thank you for watching."

---

## The One-Sentence Summary

If you had to summarize in one sentence:

> "I built the daily extraction pipeline you asked for, then extended it to handle 30 centers with randomly-generated schemas using pattern-based discovery - completing 30 extractions in 466 milliseconds."

---

## Anti-Patterns (What to Avoid)

### Don't:
- Jump straight to multi-center (no context)
- Apologize for the extension ("I know you didn't ask for this...")
- Rush through the pivot (it's the key moment)
- List features without the story arc
- End with "I guess that's it"

### Do:
- Start with the original ask (grounds the story)
- Frame the extension as initiative (not scope creep)
- Make the pivot feel natural ("But then I wondered...")
- Show genuine enthusiasm for solving the harder problem
- End with clear, confident results

---

## Practice Prompts

Before recording, answer these out loud:

1. "What were the 5 required fields in the original challenge?"
2. "Why is random schema naming a hard problem?"
3. "What does the `reviewed` flag do and why does it matter?"
4. "How long does extraction take for 30 centers?"

Being able to answer these smoothly shows you understand both systems.
